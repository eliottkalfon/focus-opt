{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization of LightGBM Using Hill Climbing and Genetic Algorithms\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this notebook, we explore hyperparameter optimization for a **LightGBM** classifier using two optimization strategies: **Hill Climbing** and **Genetic Algorithms**. LightGBM is a gradient boosting framework that uses tree-based learning algorithms. It is designed to be distributed and efficient, capable of handling large-scale data with high speed and accuracy.\n",
    "\n",
    "Our objective is to find the optimal set of hyperparameters that maximize the classification accuracy on the **Breast Cancer Wisconsin** dataset. By employing advanced optimization techniques, we aim to improve model performance beyond what can be achieved with default parameters or manual tuning.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We use the **Breast Cancer Wisconsin dataset**, which is a well-known dataset for binary classification tasks. The dataset contains **569 samples** of malignant and benign breast cancer cases, each described by **30 numerical features** that capture various properties of cell nuclei.\n",
    "\n",
    "## Hyperparameter Space\n",
    "\n",
    "We define a comprehensive hyperparameter space for the LightGBM classifier, focusing on parameters that significantly impact model performance:\n",
    "\n",
    "- **`num_leaves`**: The number of leaves in the full tree. A larger number can lead to more complex models.\n",
    "- **`max_depth`**: Maximum tree depth for base learners. Controls the complexity of the model to prevent overfitting.\n",
    "- **`learning_rate`**: Boosting learning rate. Determines the step size at each iteration while moving toward a minimum of a loss function.\n",
    "- **`n_estimators`**: Number of boosting iterations. More estimators can improve performance but increase training time.\n",
    "- **`min_child_samples`**: Minimum number of data needed in a child (leaf). Reduces overfitting by controlling leaf size.\n",
    "- **`subsample`**: Subsample ratio of the training instance. Prevents overfitting by sampling the dataset.\n",
    "- **`colsample_bytree`**: Subsample ratio of columns when constructing each tree. Similar to `subsample` but for columns.\n",
    "- **`reg_alpha`**: L1 regularization term on weights. Can be used to make the model more robust to outliers.\n",
    "- **`reg_lambda`**: L2 regularization term on weights. Can help prevent overfitting.\n",
    "\n",
    "## Optimization Methods\n",
    "\n",
    "### Hill Climbing Optimizer\n",
    "\n",
    "- **Description**: Starts with a random hyperparameter configuration and iteratively makes local changes to find better configurations.\n",
    "- **Strengths**: Simple to implement and can quickly find local optima.\n",
    "- **Challenges**: May get stuck in local optima and miss the global optimum.\n",
    "\n",
    "### Genetic Algorithm Optimizer\n",
    "\n",
    "- **Description**: Mimics the process of natural selection by maintaining a population of solutions that evolve over time using selection, crossover, and mutation.\n",
    "- **Strengths**: Can explore a wider search space and avoid local optima.\n",
    "- **Challenges**: Computationally more intensive due to the population-based approach.\n",
    "\n",
    "## Evaluation Function\n",
    "\n",
    "We define an evaluation function that:\n",
    "\n",
    "- Initializes the LightGBM classifier with the given hyperparameters using `**config` to pass parameters directly.\n",
    "- Uses **Stratified K-Fold Cross-Validation** to evaluate performance, ensuring that each fold has a similar class distribution.\n",
    "- Implements a fidelity parameter corresponding to the fold index to enable multi-fidelity optimization, balancing evaluation cost and accuracy.\n",
    "\n",
    "## Goals\n",
    "\n",
    "- **Optimize Hyperparameters**: Find the hyperparameter configuration that yields the highest classification accuracy.\n",
    "- **Compare Optimization Strategies**: Evaluate which optimization method performs better in terms of finding optimal parameters and computational efficiency.\n",
    "- **Efficient Resource Utilization**: Conduct the optimization within a predefined computational budget.\n",
    "\n",
    "## Expected Outcomes\n",
    "\n",
    "- Identification of hyperparameter configurations that improve model performance over default settings.\n",
    "- Insights into the most influential hyperparameters for LightGBM on this dataset.\n",
    "- Comparative analysis of the effectiveness of Hill Climbing and Genetic Algorithms in hyperparameter optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from typing import Dict, Any, Callable, List\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Importing necessary classes from the src module\n",
    "from focus_opt.hp_space import HyperParameterSpace, CategoricalHyperParameter, OrdinalHyperParameter, ContinuousHyperParameter\n",
    "from focus_opt.config_candidate import ConfigCandidate\n",
    "from focus_opt.helpers import OutOfBudgetError, SessionContext\n",
    "from focus_opt.optimizers import BaseOptimizer, HillClimbingOptimizer, GeneticAlgorithmOptimizer\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Define the hyperparameter space for a Gradient Boosting Classifier\n",
    "hp_space = HyperParameterSpace(\"Gradient Boosting HP Space\")\n",
    "hp_space.add_hp(CategoricalHyperParameter(name=\"loss\", values=[\"log_loss\", \"exponential\"]))\n",
    "hp_space.add_hp(OrdinalHyperParameter(name=\"n_estimators\", values=[50, 100, 150, 200]))\n",
    "hp_space.add_hp(OrdinalHyperParameter(name=\"max_depth\", values=[3, 4, 5, 6, 7]))\n",
    "hp_space.add_hp(ContinuousHyperParameter(name=\"learning_rate\", min_value=0.01, max_value=0.2))\n",
    "hp_space.add_hp(ContinuousHyperParameter(name=\"subsample\", min_value=0.5, max_value=1.0))\n",
    "hp_space.add_hp(ContinuousHyperParameter(name=\"min_samples_split\", min_value=2, max_value=20, is_int=True))\n",
    "hp_space.add_hp(ContinuousHyperParameter(name=\"min_samples_leaf\", min_value=1, max_value=20, is_int=True))\n",
    "\n",
    "# Load the Breast Cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Refactored evaluation function\n",
    "def gbm_evaluation(config: Dict[str, Any], fidelity: int) -> float:\n",
    "    \"\"\"\n",
    "    Evaluation function for a Gradient Boosting Classifier with cross-validation.\n",
    "\n",
    "    Args:\n",
    "        config (Dict[str, Any]): Configuration of hyperparameters.\n",
    "        fidelity (int): Fidelity level (index of the CV fold).\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy for the specified CV fold.\n",
    "    \"\"\"\n",
    "    logging.info(f\"Evaluating config: {config} at fidelity level: {fidelity}\")\n",
    "\n",
    "    # Initialize the Gradient Boosting Classifier with the config as **kwargs\n",
    "    clf = GradientBoostingClassifier(**config)\n",
    "\n",
    "    # Perform cross-validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "    # Get the train and test indices for the specified fold\n",
    "    for fold_index, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "        if fold_index + 1 == fidelity:\n",
    "            X_train, X_test = X[train_index], X[test_index]\n",
    "            y_train, y_test = y[train_index], y[test_index]\n",
    "            clf.fit(X_train, y_train)\n",
    "            score = clf.score(X_test, y_test)\n",
    "            logging.info(f\"Score for config {config} at fold {fidelity}: {score}\")\n",
    "            return score\n",
    "\n",
    "    raise ValueError(f\"Invalid fidelity level: {fidelity}\")\n",
    "\n",
    "# Instantiate the HillClimbingOptimizer\n",
    "hill_climbing_optimizer = HillClimbingOptimizer(\n",
    "    hp_space=hp_space,\n",
    "    evaluation_function=gbm_evaluation,\n",
    "    max_fidelity=5,\n",
    "    maximize=True,\n",
    "    log_results=True,\n",
    "    warm_start=20,\n",
    "    random_restarts=5,\n",
    ")\n",
    "# Run the Hill Climbing optimization\n",
    "best_candidate_hill_climbing = hill_climbing_optimizer.optimize(budget=500)\n",
    "print(f\"Best candidate from Hill Climbing: {best_candidate_hill_climbing.config} with score: {best_candidate_hill_climbing.evaluation_score}\")\n",
    "\n",
    "# Instantiate the GeneticAlgorithmOptimizer\n",
    "ga_optimizer = GeneticAlgorithmOptimizer(\n",
    "    hp_space=hp_space,\n",
    "    evaluation_function=gbm_evaluation,\n",
    "    max_fidelity=5,\n",
    "    maximize=True,\n",
    "    population_size=20,\n",
    "    crossover_rate=0.8,\n",
    "    mutation_rate=0.1,\n",
    "    elitism=1,\n",
    "    tournament_size=3,\n",
    "    min_population_size=5,\n",
    "    log_results=True\n",
    ")\n",
    "\n",
    "# Run the Genetic Algorithm optimization\n",
    "best_candidate_ga = ga_optimizer.optimize(budget=500)\n",
    "print(f\"Best candidate from Genetic Algorithm: {best_candidate_ga.config} with score: {best_candidate_ga.evaluation_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best candidate from Hill Climbing: {best_candidate_hill_climbing.config} with score: {best_candidate_hill_climbing.evaluation_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best candidate from Genetic Algorithm: {best_candidate_ga.config} with score: {best_candidate_ga.evaluation_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
