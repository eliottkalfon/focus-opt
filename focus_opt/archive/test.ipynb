{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.hp_space import HyperParameterSpace, BooleanHyperParameter, OrdinalHyperParameter\n",
    "\n",
    "# Define a simple hyperparameter space\n",
    "def create_simple_space():\n",
    "    hp1 = BooleanHyperParameter(name=\"use_feature_x\")\n",
    "    hp2 = OrdinalHyperParameter(name=\"model_complexity\", values=[1, 2, 3, 4, 5])\n",
    "    space = HyperParameterSpace(name=\"SimpleSpace\", hyper_parameters=[hp1, hp2])\n",
    "    return space\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_eval_function(config, indices):\n",
    "    # Simulate evaluation based on hyperparameters\n",
    "    score = 0\n",
    "    if config['use_feature_x']:\n",
    "        score += 50  # Assume using feature x gives a base score of 50\n",
    "    score += config['model_complexity'] * 10  # Each complexity level adds 10 to the score\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Configuration: {'use_feature_x': True, 'model_complexity': 5}\n",
      "Best Evaluation Score: 100.0\n",
      "Time Elapsed: 0.001306295394897461\n",
      "Total Cost: 10\n",
      "Log: [[1, 'TestRandomSearch', 0, 50.0, 0.0009980201721191406, 1], [1, 'TestRandomSearch', 0, 90.0, 0.0010170936584472656, 2], [1, 'TestRandomSearch', 0, 90.0, 0.0010271072387695312, 3], [1, 'TestRandomSearch', 0, 90.0, 0.0010340213775634766, 4], [1, 'TestRandomSearch', 0, 90.0, 0.0010409355163574219, 5], [1, 'TestRandomSearch', 0, 90.0, 0.001096963882446289, 6], [1, 'TestRandomSearch', 0, 90.0, 0.0011022090911865234, 6], [1, 'TestRandomSearch', 0, 90.0, 0.0011069774627685547, 6], [1, 'TestRandomSearch', 0, 90.0, 0.0011131763458251953, 7], [1, 'TestRandomSearch', 0, 100.0, 0.0011179447174072266, 8], [1, 'TestRandomSearch', 0, 100.0, 0.0011682510375976562, 8], [1, 'TestRandomSearch', 0, 100.0, 0.0011739730834960938, 8], [1, 'TestRandomSearch', 0, 100.0, 0.0011782646179199219, 8], [1, 'TestRandomSearch', 0, 100.0, 0.0011830329895019531, 8], [1, 'TestRandomSearch', 0, 100.0, 0.0011870861053466797, 8], [1, 'TestRandomSearch', 0, 100.0, 0.0012271404266357422, 8], [1, 'TestRandomSearch', 0, 100.0, 0.001232147216796875, 8], [1, 'TestRandomSearch', 0, 100.0, 0.0012359619140625, 8], [1, 'TestRandomSearch', 0, 100.0, 0.0012412071228027344, 9], [1, 'TestRandomSearch', 0, 100.0, 0.0012459754943847656, 9], [1, 'TestRandomSearch', 0, 100.0, 0.0012853145599365234, 10], [1, 'TestRandomSearch', 0, 100.0, 0.0012900829315185547, 10], [1, 'TestRandomSearch', 0, 100.0, 0.0012941360473632812, 10], [1, 'TestRandomSearch', 0, 100.0, 0.0012989044189453125, 10], [1, 'TestRandomSearch', 0, 100.0, 0.0013031959533691406, 10]]\n"
     ]
    }
   ],
   "source": [
    "from src.optimizers import RandomSearch\n",
    "\n",
    "def run_random_search():\n",
    "    space = create_simple_space()\n",
    "    folds = [(0)]  # Dummy folds for simplicity\n",
    "    optimizer = RandomSearch(\n",
    "        space=space,\n",
    "        eval_fold=simple_eval_function,\n",
    "        folds=folds,\n",
    "        budgets=[1],  # Evaluate each config once\n",
    "        max_budget=10,  # Total evaluations allowed\n",
    "        pop_size=5,  # Population size for random search\n",
    "        run_id=1,\n",
    "        run_name=\"TestRandomSearch\"\n",
    "    )\n",
    "    best_config, best_eval, time_elapsed, total_cost, log = optimizer.run()\n",
    "    print(\"Best Configuration:\", best_config)\n",
    "    print(\"Best Evaluation Score:\", best_eval)\n",
    "    print(\"Time Elapsed:\", time_elapsed)\n",
    "    print(\"Total Cost:\", total_cost)\n",
    "    print(\"Log:\", log)\n",
    "\n",
    "# Execute the test\n",
    "run_random_search()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
